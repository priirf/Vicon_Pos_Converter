{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 13:14:07.169375: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_0308022_moving_vertical_7-9_7-3_9-3_9-9.csv\n",
      "dataset_0308022_moving_diag_21-10_5-3.csv\n",
      "dataset_0308022_moving_vertical_17-9_17-3_20-3_20-9.csv\n",
      "dataset_0308022_moving_vertical_10-9_10-3_13-3_13-9.csv\n",
      "dataset_0308022_moving_vertical_7-9_6-3_4-3_4-9.csv\n",
      "dataset_0308022_moving_vertical_18-9_18-3_15-3_15-9.csv\n",
      "dataset_0308022_moving_edge.csv\n",
      "dataset_0308022_moving_horizontal_21-6_4-6_21-9.csv\n",
      "dataset_0308022_moving_horizontal_4-4_21-4.csv\n",
      "dataset_0308022_moving_vertical_11-9_11-3_8-3_8-9.csv\n",
      "dataset_0308022_moving_vertical_14-9_14-3_12-3_12-9.csv\n",
      "dataset_0308022_moving_vertical_14-9_14-3_16-3_17-9.csv\n",
      "dataset_0308022_moving_diag_5-11_21-3.csv\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Flatten\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.font_manager import json_dump\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "# tf.config.list_physical_devices(\"GPU\")\n",
    "# print(tf.__version__)\n",
    "# tf.test.is_gpu_available(cuda_only=True, min_cuda_compute_capability=None)\n",
    "\n",
    "data_dir = '../Dataset_sensor_floor/Dataset_Final/03082022_V2'\n",
    "#data_dir = '../../Sensorfloors/summerschool2020/test/'\n",
    "#os.path.join(dirname, train_data_dir)\n",
    "#\"path/to/training/data\"\n",
    "\n",
    "train = []\n",
    "for file in os.listdir(data_dir):\n",
    "    # Read a single file as pandas DataFrame\n",
    "    print(file)\n",
    "    df = pd.read_csv(os.path.join(data_dir, file))\n",
    "    frames = []\n",
    "    # Generate a single frame for each row\n",
    "    for index, row in df.T.items():\n",
    "        # Create dictionary with constant values (i.e. labels and frame number)\n",
    "        frame = {col: row[col] for col in df.columns if col != 'data'}\n",
    "        # Create pandas.DataFrame from Json String located in the 'data' column\n",
    "        frame['data']  = pd.read_json(row['data'])\n",
    "        frame['data']['timestamp'] = pd.to_datetime(frame['data']['timestamp'], unit='s')\n",
    "        #print(pd.to_datetime(frame['data']['timestamp'], unit='ms'))\n",
    "        frames.append(frame)\n",
    "    train.append(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[12][900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_i = train[0][0]['data']['timestamp']\n",
    "print(np.argmax(timestamp_i), timestamp_i[220])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the range of min-max RSSI values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_len = 0\n",
    "rssi_max_frame = []\n",
    "rssi_min_frame = []\n",
    "rssi_max_threshold = []\n",
    "rssi_min_threshold = []\n",
    "\n",
    "\n",
    "for i in range(len(train)):\n",
    "    for j in range(len(train[i])):\n",
    "        rssi = train[i][j]['data']['r']\n",
    "        rssi_min_frame.append(min(rssi))\n",
    "        rssi_max_frame.append(max(rssi))\n",
    "        #print(\"iteration: \", i, j, \"val: \", min(rssi), min(rssi))\n",
    "        \n",
    "    rssi_min_threshold.append(min(rssi_min_frame))\n",
    "    rssi_max_threshold.append(max(rssi_max_frame))\n",
    "    print(\"train iteration: \", i, \"val: \", min(rssi_min_frame),max(rssi_max_frame))\n",
    "    rssi_min_frame.clear()\n",
    "    rssi_max_frame.clear()\n",
    "\n",
    "rssi_low_treshold = min(rssi_min_threshold)\n",
    "rssi_upper_treshold = max(rssi_max_threshold)\n",
    "print(\"train iteration: \", i, \"val: \", rssi_low_treshold, rssi_upper_treshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Min Max scaler to normalize RSSI values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9494400\n"
     ]
    }
   ],
   "source": [
    "rssi_values = []\n",
    "for i in range(len(train)):\n",
    "    for j in range(len(train[i])):\n",
    "        for k in range(len(train[i][j]['data']['r'])):\n",
    "            #rssi = train[i][j]['data']['r'][k]\n",
    "            rssi_values.append(train[i][j]['data']['r'][k])\n",
    "        #     rssi_values\n",
    "        #\n",
    "        #print(len(train[i][j]['data']['r']))\n",
    "print(len(rssi_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_rssi = MinMaxScaler(feature_range=(0, 1))\n",
    "rssi_values_reshape = np.asarray(rssi_values)\n",
    "rssi_values_reshape = rssi_values_reshape.reshape([-1,1])\n",
    "scaler_rssi = scaler_rssi.fit(rssi_values_reshape)\n",
    "norm_rssi = scaler_rssi.transform(rssi_values_reshape)\n",
    "\n",
    "pickle.dump(scaler_rssi, open('output/scaler_rssi.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_rssi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
